# LLM provider selection: gemini | local | openai | anthropic
LLM_PROVIDER=gemini

# Common limits
MAX_TOKENS_PER_CALL=2000
CHUNK_TOKENS_TARGET=1200
CHUNK_OVERLAP_TOKENS=200

# Gemini (Google Generative AI)
GOOGLE_API_KEY=
GEMINI_MODEL=gemini-1.5-pro

# OpenAI settings (optional)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=

# Anthropic settings (optional)
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-3-5-sonnet-latest

# Local settings (e.g., Ollama)
LOCAL_LLM_MODEL=llama3.1
LOCAL_LLM_BASE_URL=http://localhost:11434

# Security
ALLOWED_FILE_EXT=.java,.xml,.properties,.yml,.yaml,.gradle,.md
EXCLUDED_DIRS=.git,node_modules,build,target,.idea,.vscode,.mvn

# Logging Configuration
AI2NODE_LOG_LEVEL=INFO  # DEBUG | INFO | WARN | ERROR
AI2NODE_LOG_FILE=Output/Reports/app.log
